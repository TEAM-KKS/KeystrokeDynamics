{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils.ipynb \n",
    "%run models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/clean_union_fe_c2_04_28_20_21_00.csv')\n",
    "# df = pd.read_csv('data/clean_union_fe_c2_04_28_20_21_00.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = Models(df.copy(), 0.2, False)\n",
    "models_b = Models(df.copy(), 0.2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>train_perc</th>\n",
       "      <th>test_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>648</td>\n",
       "      <td>519</td>\n",
       "      <td>129</td>\n",
       "      <td>0.800926</td>\n",
       "      <td>0.199074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>952</td>\n",
       "      <td>762</td>\n",
       "      <td>190</td>\n",
       "      <td>0.800420</td>\n",
       "      <td>0.199580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>624</td>\n",
       "      <td>499</td>\n",
       "      <td>125</td>\n",
       "      <td>0.799679</td>\n",
       "      <td>0.200321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1208</td>\n",
       "      <td>966</td>\n",
       "      <td>242</td>\n",
       "      <td>0.799669</td>\n",
       "      <td>0.200331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>825</td>\n",
       "      <td>660</td>\n",
       "      <td>165</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>659</td>\n",
       "      <td>527</td>\n",
       "      <td>132</td>\n",
       "      <td>0.799697</td>\n",
       "      <td>0.200303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>657</td>\n",
       "      <td>526</td>\n",
       "      <td>131</td>\n",
       "      <td>0.800609</td>\n",
       "      <td>0.199391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>725</td>\n",
       "      <td>580</td>\n",
       "      <td>145</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>614</td>\n",
       "      <td>491</td>\n",
       "      <td>123</td>\n",
       "      <td>0.799674</td>\n",
       "      <td>0.200326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1610</td>\n",
       "      <td>1288</td>\n",
       "      <td>322</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>950</td>\n",
       "      <td>760</td>\n",
       "      <td>190</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>703</td>\n",
       "      <td>562</td>\n",
       "      <td>141</td>\n",
       "      <td>0.799431</td>\n",
       "      <td>0.200569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1098</td>\n",
       "      <td>878</td>\n",
       "      <td>220</td>\n",
       "      <td>0.799636</td>\n",
       "      <td>0.200364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1084</td>\n",
       "      <td>867</td>\n",
       "      <td>217</td>\n",
       "      <td>0.799815</td>\n",
       "      <td>0.200185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>786</td>\n",
       "      <td>629</td>\n",
       "      <td>157</td>\n",
       "      <td>0.800254</td>\n",
       "      <td>0.199746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    total  train  test  train_perc  test_perc\n",
       "0     648    519   129    0.800926   0.199074\n",
       "1     952    762   190    0.800420   0.199580\n",
       "2     624    499   125    0.799679   0.200321\n",
       "3    1208    966   242    0.799669   0.200331\n",
       "4     825    660   165    0.800000   0.200000\n",
       "5     659    527   132    0.799697   0.200303\n",
       "6     657    526   131    0.800609   0.199391\n",
       "7     725    580   145    0.800000   0.200000\n",
       "8     614    491   123    0.799674   0.200326\n",
       "9    1610   1288   322    0.800000   0.200000\n",
       "10    950    760   190    0.800000   0.200000\n",
       "11    703    562   141    0.799431   0.200569\n",
       "12   1098    878   220    0.799636   0.200364\n",
       "13   1084    867   217    0.799815   0.200185\n",
       "14    786    629   157    0.800254   0.199746"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = pd.DataFrame(list(zip(models.df['name'].value_counts().sort_index(), models.y_train.value_counts().sort_index(), models.y_test.value_counts().sort_index())), columns=['total','train','test'])\n",
    "split['train_perc'] = split['train']/(split['train']+split['test'])\n",
    "split['test_perc'] = split['test']/(split['train']+split['test'])\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>train_perc</th>\n",
       "      <th>test_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>648</td>\n",
       "      <td>491</td>\n",
       "      <td>123</td>\n",
       "      <td>0.799674</td>\n",
       "      <td>0.200326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>952</td>\n",
       "      <td>491</td>\n",
       "      <td>123</td>\n",
       "      <td>0.799674</td>\n",
       "      <td>0.200326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>624</td>\n",
       "      <td>491</td>\n",
       "      <td>123</td>\n",
       "      <td>0.799674</td>\n",
       "      <td>0.200326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1208</td>\n",
       "      <td>491</td>\n",
       "      <td>123</td>\n",
       "      <td>0.799674</td>\n",
       "      <td>0.200326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>825</td>\n",
       "      <td>491</td>\n",
       "      <td>123</td>\n",
       "      <td>0.799674</td>\n",
       "      <td>0.200326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>659</td>\n",
       "      <td>492</td>\n",
       "      <td>122</td>\n",
       "      <td>0.801303</td>\n",
       "      <td>0.198697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>657</td>\n",
       "      <td>491</td>\n",
       "      <td>123</td>\n",
       "      <td>0.799674</td>\n",
       "      <td>0.200326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>725</td>\n",
       "      <td>492</td>\n",
       "      <td>122</td>\n",
       "      <td>0.801303</td>\n",
       "      <td>0.198697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>614</td>\n",
       "      <td>491</td>\n",
       "      <td>123</td>\n",
       "      <td>0.799674</td>\n",
       "      <td>0.200326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1610</td>\n",
       "      <td>491</td>\n",
       "      <td>123</td>\n",
       "      <td>0.799674</td>\n",
       "      <td>0.200326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>950</td>\n",
       "      <td>491</td>\n",
       "      <td>123</td>\n",
       "      <td>0.799674</td>\n",
       "      <td>0.200326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>703</td>\n",
       "      <td>492</td>\n",
       "      <td>122</td>\n",
       "      <td>0.801303</td>\n",
       "      <td>0.198697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1098</td>\n",
       "      <td>491</td>\n",
       "      <td>123</td>\n",
       "      <td>0.799674</td>\n",
       "      <td>0.200326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1084</td>\n",
       "      <td>491</td>\n",
       "      <td>123</td>\n",
       "      <td>0.799674</td>\n",
       "      <td>0.200326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>786</td>\n",
       "      <td>491</td>\n",
       "      <td>123</td>\n",
       "      <td>0.799674</td>\n",
       "      <td>0.200326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    total  train  test  train_perc  test_perc\n",
       "0     648    491   123    0.799674   0.200326\n",
       "1     952    491   123    0.799674   0.200326\n",
       "2     624    491   123    0.799674   0.200326\n",
       "3    1208    491   123    0.799674   0.200326\n",
       "4     825    491   123    0.799674   0.200326\n",
       "5     659    492   122    0.801303   0.198697\n",
       "6     657    491   123    0.799674   0.200326\n",
       "7     725    492   122    0.801303   0.198697\n",
       "8     614    491   123    0.799674   0.200326\n",
       "9    1610    491   123    0.799674   0.200326\n",
       "10    950    491   123    0.799674   0.200326\n",
       "11    703    492   122    0.801303   0.198697\n",
       "12   1098    491   123    0.799674   0.200326\n",
       "13   1084    491   123    0.799674   0.200326\n",
       "14    786    491   123    0.799674   0.200326"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_bal = pd.DataFrame(list(zip(models_b.df['name'].value_counts().sort_index(), models_b.y_train.value_counts().sort_index(), models_b.y_test.value_counts().sort_index())), columns=['total','train','test'])\n",
    "split_bal['train_perc'] = split_bal['train']/(split_bal['train']+split_bal['test'])\n",
    "split_bal['test_perc'] = split_bal['test']/(split_bal['train']+split_bal['test'])\n",
    "split_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_balanced_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb, y_pred = models.NB()\n",
    "models.accuracy_score(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.04      0.07       129\n",
      "           1       0.18      0.25      0.21       190\n",
      "           2       0.49      0.42      0.45       125\n",
      "           3       0.29      0.05      0.08       242\n",
      "           4       0.39      0.50      0.44       165\n",
      "           5       0.44      0.06      0.11       132\n",
      "           6       0.34      0.69      0.46       131\n",
      "           7       0.23      0.87      0.37       145\n",
      "           8       0.41      0.24      0.31       123\n",
      "           9       1.00      1.00      1.00       322\n",
      "          10       0.51      0.44      0.47       190\n",
      "          11       0.25      0.75      0.37       141\n",
      "          12       0.34      0.05      0.09       220\n",
      "          13       0.51      0.28      0.36       217\n",
      "          14       0.40      0.10      0.16       157\n",
      "\n",
      "    accuracy                           0.40      2629\n",
      "   macro avg       0.41      0.38      0.33      2629\n",
      "weighted avg       0.44      0.40      0.36      2629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(models.classification_report(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model_results.append(models.class_score(y_pred, 'Naive Bayes'))\n",
    "# model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb, y_pred = models_b.NB()\n",
    "models_b.accuracy_score(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.76      0.57       123\n",
      "           1       0.19      0.21      0.20       123\n",
      "           2       0.57      0.48      0.52       123\n",
      "           3       0.08      0.01      0.01       123\n",
      "           4       0.41      0.55      0.47       123\n",
      "           5       0.47      0.07      0.13       122\n",
      "           6       0.41      0.20      0.26       123\n",
      "           7       0.26      0.76      0.38       122\n",
      "           8       0.51      0.32      0.39       123\n",
      "           9       1.00      0.99      1.00       123\n",
      "          10       0.50      0.43      0.46       123\n",
      "          11       0.30      0.76      0.43       122\n",
      "          12       0.44      0.14      0.21       123\n",
      "          13       0.45      0.24      0.32       123\n",
      "          14       0.36      0.16      0.22       123\n",
      "\n",
      "    accuracy                           0.41      1842\n",
      "   macro avg       0.43      0.41      0.37      1842\n",
      "weighted avg       0.43      0.41      0.37      1842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(models_b.classification_report(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_balanced_results = model_balanced_results.append(models_b.class_score(y_pred, 'Naive Bayes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr, y_pred = models.LR()\n",
    "models.accuracy_score(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       129\n",
      "           1       0.06      0.01      0.02       190\n",
      "           2       0.00      0.00      0.00       125\n",
      "           3       0.14      0.74      0.24       242\n",
      "           4       0.12      0.25      0.16       165\n",
      "           5       0.06      0.10      0.07       132\n",
      "           6       0.00      0.00      0.00       131\n",
      "           7       0.00      0.00      0.00       145\n",
      "           8       0.00      0.00      0.00       123\n",
      "           9       0.36      0.78      0.49       322\n",
      "          10       0.15      0.02      0.04       190\n",
      "          11       0.00      0.00      0.00       141\n",
      "          12       0.00      0.00      0.00       220\n",
      "          13       0.00      0.00      0.00       217\n",
      "          14       0.00      0.00      0.00       157\n",
      "\n",
      "    accuracy                           0.19      2629\n",
      "   macro avg       0.06      0.13      0.07      2629\n",
      "weighted avg       0.08      0.19      0.10      2629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(models.classification_report(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model_results.append(models.class_score(y_pred, 'Logistic Regression'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr, y_pred = models_b.LR()\n",
    "models_b.accuracy_score(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.55      0.40       123\n",
      "           1       0.06      0.01      0.01       123\n",
      "           2       0.17      0.26      0.21       123\n",
      "           3       0.00      0.00      0.00       123\n",
      "           4       0.12      0.29      0.17       123\n",
      "           5       0.09      0.23      0.13       122\n",
      "           6       0.00      0.00      0.00       123\n",
      "           7       0.12      0.34      0.18       122\n",
      "           8       0.10      0.19      0.13       123\n",
      "           9       0.00      0.00      0.00       123\n",
      "          10       0.00      0.00      0.00       123\n",
      "          11       0.15      0.18      0.16       122\n",
      "          12       0.08      0.02      0.03       123\n",
      "          13       0.00      0.00      0.00       123\n",
      "          14       0.09      0.01      0.01       123\n",
      "\n",
      "    accuracy                           0.14      1842\n",
      "   macro avg       0.09      0.14      0.10      1842\n",
      "weighted avg       0.09      0.14      0.10      1842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(models_b.classification_report(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_balanced_results = model_balanced_results.append(models_b.class_score(y_pred, 'Logistic Regression'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of nodes 5772\n",
      "Average maximum depth 30\n",
      "hold_for                   0.202076\n",
      "platform                   0.141181\n",
      "pressed_after              0.131353\n",
      "effort                     0.130764\n",
      "speed                      0.118506\n",
      "key_pressed                0.105809\n",
      "device_type                0.074254\n",
      "box_id                     0.041147\n",
      "false_character            0.031893\n",
      "type_combination           0.023018\n",
      "long_pressed_equivalent    0.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf, y_pred = models.RF()\n",
    "models.accuracy_score(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.64      0.65       129\n",
      "           1       0.76      0.87      0.81       190\n",
      "           2       0.65      0.86      0.74       125\n",
      "           3       0.63      0.86      0.73       242\n",
      "           4       0.67      0.72      0.69       165\n",
      "           5       0.56      0.29      0.38       132\n",
      "           6       0.62      0.46      0.53       131\n",
      "           7       0.44      0.37      0.40       145\n",
      "           8       0.61      0.46      0.52       123\n",
      "           9       1.00      1.00      1.00       322\n",
      "          10       0.68      0.57      0.62       190\n",
      "          11       0.67      0.58      0.62       141\n",
      "          12       0.78      0.89      0.83       220\n",
      "          13       0.82      0.86      0.84       217\n",
      "          14       0.60      0.57      0.58       157\n",
      "\n",
      "    accuracy                           0.71      2629\n",
      "   macro avg       0.68      0.67      0.66      2629\n",
      "weighted avg       0.71      0.71      0.70      2629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(models.classification_report(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model_results.append(models.class_score(y_pred, 'Random Forest'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of nodes 4486\n",
      "Average maximum depth 28\n",
      "hold_for                   0.210598\n",
      "pressed_after              0.136050\n",
      "effort                     0.134806\n",
      "speed                      0.122953\n",
      "platform                   0.117073\n",
      "key_pressed                0.109740\n",
      "device_type                0.066355\n",
      "box_id                     0.044252\n",
      "false_character            0.033011\n",
      "type_combination           0.025163\n",
      "long_pressed_equivalent    0.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf, y_pred = models_b.RF()\n",
    "models_b.accuracy_score(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.65      0.60       123\n",
      "           1       0.66      0.56      0.61       123\n",
      "           2       0.63      0.68      0.65       123\n",
      "           3       0.49      0.46      0.48       123\n",
      "           4       0.53      0.63      0.58       123\n",
      "           5       0.41      0.35      0.38       122\n",
      "           6       0.52      0.38      0.44       123\n",
      "           7       0.38      0.37      0.37       122\n",
      "           8       0.57      0.60      0.58       123\n",
      "           9       1.00      1.00      1.00       123\n",
      "          10       0.58      0.49      0.53       123\n",
      "          11       0.61      0.63      0.62       122\n",
      "          12       0.63      0.67      0.65       123\n",
      "          13       0.68      0.66      0.67       123\n",
      "          14       0.51      0.60      0.55       123\n",
      "\n",
      "    accuracy                           0.58      1842\n",
      "   macro avg       0.58      0.58      0.58      1842\n",
      "weighted avg       0.58      0.58      0.58      1842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(models_b.classification_report(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_balanced_results = model_balanced_results.append(models_b.class_score(y_pred, 'Random Forest'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svm, y_pred = models.SVM()\n",
    "models.accuracy_score(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models.classification_report(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model_results.append(models.class_score(y_pred, 'SVM'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm, y_pred = models_b.SVM()\n",
    "models_b.accuracy_score(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models_b.classification_report(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_balanced_results = model_balanced_results.append(models_b.class_score(y_pred, 'SVM'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn, y_pred = models.KNN()\n",
    "models.accuracy_score(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models.classification_report(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model_results.append(models.class_score(y_pred, 'KNN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn, y_pred = models_b.KNN()\n",
    "models_b.accuracy_score(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(models_b.classification_report(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_balanced_results = model_balanced_results.append(models_b.class_score(y_pred, 'KNN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(model.feature_importances_,index=X_train.columns).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,9))\n",
    "plt.title('Plot of Users vs Truth for unbalanced classification models')\n",
    "sns.lineplot(x='user_id', y='truth', hue='model_name', style='model_name', data=model_results, markers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,9))\n",
    "plt.title('Plot of Users vs Truth for Balanced classification models')\n",
    "sns.lineplot(x='user_id', y='truth', hue='model_name', style='model_name', data=model_balanced_results, markers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
